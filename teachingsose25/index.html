<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Teaching - Marion Di Marco   (née Weller)</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="Teaching" />
<meta property="og:description" content="Sommer Semester 2025
Generative Models on Text — Large Language Models Large Language Models (such as GPT2, GPT3, GPT4, Llama, T5) and Intelligent Chatbots (such as ChatGPT, Claude, Gemini and Copilot) are a very timely topic.
Contents: N-gram language models, neural language modeling, word2vec, RNNs, Transformers, BERT, RLHF, ChatGPT, multilingual alignment, prompting, transfer learning, domain adaptation, linguistic knowledge in large language models
Location: Room D.2.11
Time: Tuesday 16:15 &ndash; 17:45" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mariondimarco.github.io/teachingsose25/" /><meta property="article:section" content="" />
<meta property="article:published_time" content="2019-04-19T21:37:58+05:30" />
<meta property="article:modified_time" content="2019-04-19T21:37:58+05:30" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Teaching"/>
<meta name="twitter:description" content="Sommer Semester 2025
Generative Models on Text — Large Language Models Large Language Models (such as GPT2, GPT3, GPT4, Llama, T5) and Intelligent Chatbots (such as ChatGPT, Claude, Gemini and Copilot) are a very timely topic.
Contents: N-gram language models, neural language modeling, word2vec, RNNs, Transformers, BERT, RLHF, ChatGPT, multilingual alignment, prompting, transfer learning, domain adaptation, linguistic knowledge in large language models
Location: Room D.2.11
Time: Tuesday 16:15 &ndash; 17:45"/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="https://mariondimarco.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://mariondimarco.github.io/css/main.css" /><link rel="stylesheet" type="text/css" href="https://mariondimarco.github.io/css/dark.css" media="(prefers-color-scheme: dark)" />

	
	<script src="https://mariondimarco.github.io/js/main.js"></script>
</head>

<body>
	<div class="container wrapper post">
		<div class="header">
	<h1 class="site-title"><a href="/">Marion Di Marco   (née Weller)</a></h1>
	<div class="site-description"><h2>Post-Doc Researcher at TUM (School of Computation, Information and Technology)</h2><nav class="nav social">
			<ul class="flat"></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/home">Home</a>
			</li>
			
			<li>
				<a href="/publications">Publications</a>
			</li>
			
			<li>
				<a href="/teaching">Teaching</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post-header">
			<h1 class="title">Teaching</h1>
		</div>

		<div class="markdown">
			<p><strong>Sommer Semester 2025</strong></p>
<h3 id="generative-models-on-text---large-language-models"><strong>Generative Models on Text</strong>  — <strong>Large Language Models</strong></h3>
<p>Large Language Models (such as GPT2, GPT3, GPT4, Llama, T5) and Intelligent Chatbots (such as ChatGPT, Claude, Gemini and Copilot) are a very timely topic.</p>
<p>Contents:
N-gram language models, neural language modeling, word2vec, RNNs, Transformers, BERT, RLHF, ChatGPT, multilingual alignment, prompting, transfer learning, domain adaptation, linguistic knowledge in large language models</p>
<hr>
<p><strong>Location:</strong>
Room D.2.11</p>
<p><strong>Time:</strong>
Tuesday 16:15 &ndash; 17:45</p>
<hr>
<p><strong>Lectures</strong></p>
<p>Lecture 1: <a href="https://mariondimarco.github.io/Lectures/Organization_SoSe25.pdf">Organization</a> and <a href="https://mariondimarco.github.io/Lectures/lecture_Introduction_SoSe25.pdf">Introduction to Linguistic Concepts</a></p>
<p>Lecture 2: <a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">N-gram Models</a> (without section 3.7)
<a href="https://mariondimarco.github.io/Lectures/lecture_ngrams_SoSe25.pdf">Slides</a></p>
<p>Lecture 3: <a href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">Bengio et al. (2003): A Neural Probabilistic Language Model.</a></p>
<p>Lecture 4: Talk by Prof. Victoria Nash: <a href="https://chn.tum.de/event/event/ai-and-evolution-of-digital-childhood">AI and the Evolution of Digital Childhood</a>. <br>
       May 20, 2025  16:15-18:00  in Room D.0.0.1</p>
<p>Lecture 5: <a href="https://arxiv.org/abs/1902.06006">Smith (2019): Contextual Word Representations: A Contextual Introduction</a></p>
<hr>
<p><strong>Literature</strong></p>
<p><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a><br>
Dan Jurafsky and James H. Martin (2024; 3rd ed. draft)</p>
<hr>
<p><strong>Paper Presentations</strong></p>

		</div>

		<div class="post-tags">
			
		</div></div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> © Copyright notice |  <a href="https://github.com/vividvilla/ezhil">Ezhil theme</a> | Built with <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>


</body>
</html>
